{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a05959-a3c5-43bf-a020-fb34783fa9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required libraries\n",
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig\n",
    "import os\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573c0958-9a6a-4739-87eb-ed565397c668",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set the CUDA_VISIBLE_DEVICES environment variable to specify GPU devices\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"  # Use GPU devices 0 and 1\n",
    "\n",
    "from flask import Flask, request, jsonify\n",
    "from langchain.llms.huggingface_pipeline import HuggingFacePipeline\n",
    "import torch\n",
    "import time\n",
    "import re \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b98b144-9b56-4675-85e0-c9fe886af816",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final_test= pd.read_csv(\"data_final_test.csv\")\n",
    "len(data_final_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b85f3e-a642-4445-8a1f-642bfea9df52",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848daf46-4c42-4d7d-b09b-1b9ba7488af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id=\"LLaMa2_13B_Chat-finetuned-New_annotations_v10\"\n",
    "# model_id=\"llama-2-13b-chat-hf\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83128af3-7561-4503-af6f-5532c6edf598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model and the tokenizer. Set generation config\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    low_cpu_mem_usage=True,\n",
    "    return_dict=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\")\n",
    "\n",
    "\n",
    "generation_config = GenerationConfig(\n",
    "    do_sample=True,\n",
    "    top_k=1,\n",
    "    temperature=0.1,\n",
    "    max_new_tokens=300,\n",
    "    pad_token_id=tokenizer.eos_token_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d915d94-0e12-45bc-b592-6d66d6fe90ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_question(question_prompt):\n",
    "    inputs = tokenizer(question_prompt, return_tensors=\"pt\", padding=True, truncation=True,max_length= 2048).to(\"cuda\")\n",
    "    outputs = model.generate(**inputs, generation_config=generation_config)\n",
    "    answer = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7711bdbf-daf5-45fe-867c-8053d377d4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_answers = []\n",
    "val_data_prompts = list(data_final_test['text'])\n",
    "\n",
    "for i in tqdm.tqdm(range(0, len(val_data_prompts), 1)):\n",
    "    question_prompts = val_data_prompts[i:i+1]\n",
    "    ans = solve_question(question_prompts)\n",
    "\n",
    "    all_answers.extend(ans)\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58cd0d6-14cc-48f5-ba38-6f0e2fb8a5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bfc8a7-6bc0-4d28-8732-672a27a71d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a984874-e076-4a26-b0a5-7e7cda690cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final_test['Result_Finetuned'] = all_answers\n",
    "data_final_test.to_csv('data_final_test.csv', index=False)\n",
    "data_final_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc85530-cc3a-43ec-8e90-c2a4be366a6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e461894-d9b0-466a-907b-cb288cc02c87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
