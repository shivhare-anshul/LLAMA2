{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e8da3c-708f-4d00-9949-cb504e03e7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_final_test = 'data_final_test.csv'\n",
    "data_final_train = 'data_final_train.csv'\n",
    "\n",
    "# Read the Excel file\n",
    "data_final_test = pd.read_csv(data_final_test)\n",
    "data_final_train = pd.read_csv(data_final_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467f6e03-b3d2-44ca-9b13-af23524a1d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "data_final_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb2124e-c688-47e7-aa77-91ba38a6d612",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e08040-63e4-4b55-983a-cfe79d54533d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from peft import LoraConfig, prepare_model_for_kbit_training, get_peft_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095e7691-6b74-4c49-8f2f-668464f9b403",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Dataset.from_pandas(data_final_train)\n",
    "eval_dataset = Dataset.from_pandas(data_final_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f687ebe-65ae-4285-8f65-489e843b5fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id=\"llama-2-13b-chat-hf\"\n",
    "use_flash_attention = False\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63f786e-b303-4f08-862c-305891c1df9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=False,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    ")\n",
    "\n",
    "# Load model\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    quantization_config=bnb_config,\n",
    "    use_cache=False,\n",
    "    use_flash_attention_2=use_flash_attention,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20af559e-d0f2-47cf-acdd-251f94bb269d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.pretraining_tp = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a801a46-55e3-43e4-895c-6ca634297012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LoRA config based on QLoRA paper\n",
    "peft_config = LoraConfig(\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.05,\n",
    "    r=64,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=[\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\"]\n",
    ")\n",
    "# Prepare model for training\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "model = get_peft_model(model, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb0386c-08d6-404f-9a8b-f82b7ace7a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir=\"LLaMa2_13B_Chat-finetuned-New_annotations_v10\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=1,\n",
    "    gradient_checkpointing=True,\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    logging_steps=100,\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-4,\n",
    "    fp16=True,\n",
    "    # max_grad_norm=0.3,\n",
    "    # warmup_ratio=0.03,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    disable_tqdm=False,\n",
    "    push_to_hub=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c61c1f-b5e7-4b4c-a5ae-a2f2f3ee5085",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import SFTTrainer\n",
    "\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=data,\n",
    "    # eval_dataset=eval_dataset,\n",
    "    dataset_text_field=\"text\",\n",
    "    peft_config=peft_config,\n",
    "    max_seq_length=2048,\n",
    "    tokenizer=tokenizer,\n",
    "    packing=True,\n",
    "    # formatting_func=format_prompt,\n",
    "    args=training_arguments,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedaaa81-9c76-4bd7-a57d-72fcd521033a",
   "metadata": {},
   "outputs": [],
   "source": [
    "refined_model = \"LLaMa2_13B_Chat-finetuned-New_annotations_v10\"\n",
    "# Train\n",
    "trainer.train()\n",
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5762c894-bcab-41ac-b425-3594ca224695",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model.save_pretrained(refined_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8579ee-4d60-4a80-9adc-d08e12dbea56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5755c804-c771-4927-8415-57036bb4e163",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41428f41-16d5-46d3-bf84-7bc6445fa215",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b41ec20-77bd-4b44-b317-f35196ed791e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# incorporating our adapter weights into the base model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1934d3e2-02ab-4c76-beb8-6fbea6e95e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import AutoPeftModelForCausalLM\n",
    "\n",
    "model = AutoPeftModelForCausalLM.from_pretrained(\n",
    "    training_arguments.output_dir,\n",
    "    low_cpu_mem_usage=True,\n",
    ")\n",
    "\n",
    "# Merge LoRA and base model\n",
    "merged_model = model.merge_and_unload()\n",
    "\n",
    "# Save the merged model\n",
    "merged_model.save_pretrained(\"merged_LLaMa2_13B_Chat-finetuned_New_annotations_v10_vllm\", safe_serialization=True)\n",
    "tokenizer.save_pretrained(\"merged_LLaMa2_13B_Chat-finetuned_New_annotations_v10_vllm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43089c88-7ac5-452c-bf80-3a72ed48fa39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
